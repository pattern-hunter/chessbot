{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db9fd6d7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-18T12:19:10.101623Z",
     "iopub.status.busy": "2025-05-18T12:19:10.101356Z",
     "iopub.status.idle": "2025-05-18T12:19:23.004325Z",
     "shell.execute_reply": "2025-05-18T12:19:23.003467Z"
    },
    "papermill": {
     "duration": 12.907356,
     "end_time": "2025-05-18T12:19:23.005504",
     "exception": false,
     "start_time": "2025-05-18T12:19:10.098148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-chess\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading python_chess-1.999-py3-none-any.whl.metadata (776 bytes)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chess<2,>=1 (from python-chess)\r\n",
      "  Downloading chess-1.11.2.tar.gz (6.1 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/6.1 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/6.1 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Downloading python_chess-1.999-py3-none-any.whl (1.4 kB)\r\n",
      "Building wheels for collected packages: chess\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for chess (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for chess: filename=chess-1.11.2-py3-none-any.whl size=147775 sha256=0183353a944476bad6161c170e663859c5d5946cda99d743a1ec6687b2143a26\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/fb/5d/5c/59a62d8a695285e59ec9c1f66add6f8a9ac4152499a2be0113\r\n",
      "Successfully built chess\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: chess, python-chess\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed chess-1.11.2 python-chess-1.999\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfulll\n",
      "True\n",
      "Tesla T4\n",
      "Successfull\n"
     ]
    }
   ],
   "source": [
    "!pip install python-chess\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import chess\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from timeit import default_timer as timer\n",
    "import pickle\n",
    "import psutil\n",
    "\n",
    "# 1. Setup\n",
    "# 1.1 Thiết lập các đường dẫn thư mục\n",
    "DATA_PATH = \"/kaggle/input/chess-games/chess_games.csv\"\n",
    "\n",
    "# 1.2 Kiểm tra GPU\n",
    "print(\"Successfulll\")\n",
    "print(torch.cuda.is_available())  # True nếu GPU hoạt động\n",
    "print(torch.cuda.get_device_name(0))  # Tên GPU (ví dụ: T4)\n",
    "print(\"Successfull\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d67c5a82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T12:19:23.011325Z",
     "iopub.status.busy": "2025-05-18T12:19:23.010974Z",
     "iopub.status.idle": "2025-05-18T12:23:08.894151Z",
     "shell.execute_reply": "2025-05-18T12:23:08.893259Z"
    },
    "papermill": {
     "duration": 225.887691,
     "end_time": "2025-05-18T12:23:08.895714",
     "exception": false,
     "start_time": "2025-05-18T12:19:23.008023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tạo dữ liệu mới và ghi đè file .pkl...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số ván cờ sau khi lọc: 57395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số ván cờ trong game_list: 57326\n",
      "Số ván cờ bị bỏ qua do lỗi: 8015\n",
      "RAM available: 25.10 GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 0 tại: /kaggle/working/chess_data.pkl_batch_0.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 1 tại: /kaggle/working/chess_data.pkl_batch_1.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 2 tại: /kaggle/working/chess_data.pkl_batch_2.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 3 tại: /kaggle/working/chess_data.pkl_batch_3.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 4 tại: /kaggle/working/chess_data.pkl_batch_4.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 5 tại: /kaggle/working/chess_data.pkl_batch_5.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 6 tại: /kaggle/working/chess_data.pkl_batch_6.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 7 tại: /kaggle/working/chess_data.pkl_batch_7.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 8 tại: /kaggle/working/chess_data.pkl_batch_8.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 9 tại: /kaggle/working/chess_data.pkl_batch_9.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 10 tại: /kaggle/working/chess_data.pkl_batch_10.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 11 tại: /kaggle/working/chess_data.pkl_batch_11.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 12 tại: /kaggle/working/chess_data.pkl_batch_12.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 13 tại: /kaggle/working/chess_data.pkl_batch_13.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 14 tại: /kaggle/working/chess_data.pkl_batch_14.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 15 tại: /kaggle/working/chess_data.pkl_batch_15.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 16 tại: /kaggle/working/chess_data.pkl_batch_16.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 17 tại: /kaggle/working/chess_data.pkl_batch_17.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 18 tại: /kaggle/working/chess_data.pkl_batch_18.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 19 tại: /kaggle/working/chess_data.pkl_batch_19.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 20 tại: /kaggle/working/chess_data.pkl_batch_20.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 21 tại: /kaggle/working/chess_data.pkl_batch_21.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 22 tại: /kaggle/working/chess_data.pkl_batch_22.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 23 tại: /kaggle/working/chess_data.pkl_batch_23.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 24 tại: /kaggle/working/chess_data.pkl_batch_24.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 25 tại: /kaggle/working/chess_data.pkl_batch_25.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 26 tại: /kaggle/working/chess_data.pkl_batch_26.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 27 tại: /kaggle/working/chess_data.pkl_batch_27.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 28 tại: /kaggle/working/chess_data.pkl_batch_28.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 29 tại: /kaggle/working/chess_data.pkl_batch_29.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 30 tại: /kaggle/working/chess_data.pkl_batch_30.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 31 tại: /kaggle/working/chess_data.pkl_batch_31.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 32 tại: /kaggle/working/chess_data.pkl_batch_32.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 33 tại: /kaggle/working/chess_data.pkl_batch_33.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 34 tại: /kaggle/working/chess_data.pkl_batch_34.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 35 tại: /kaggle/working/chess_data.pkl_batch_35.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 36 tại: /kaggle/working/chess_data.pkl_batch_36.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 37 tại: /kaggle/working/chess_data.pkl_batch_37.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 38 tại: /kaggle/working/chess_data.pkl_batch_38.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 39 tại: /kaggle/working/chess_data.pkl_batch_39.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 40 tại: /kaggle/working/chess_data.pkl_batch_40.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch 41 tại: /kaggle/working/chess_data.pkl_batch_41.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu batch cuối tại: /kaggle/working/chess_data.pkl\n",
      "Đã lưu toàn bộ move_to_idx và idx_to_move tại: /kaggle/working/move_mappings.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số mẫu: 4261971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "move_to_idx (5 mục đầu tiên):\n",
      "{'e2e4': 0, 'c7c5': 1, 'g1f3': 2, 'd7d6': 3, 'd2d4': 4}\n",
      "Tổng số mục trong move_to_idx: 1877\n",
      "\n",
      "idx_to_move (5 mục đầu tiên):\n",
      "{0: 'e2e4', 1: 'c7c5', 2: 'g1f3', 3: 'd7d6', 4: 'd2d4'}\n",
      "Tổng số mục trong idx_to_move: 1877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng mini-batches train: 53275\n",
      "Kích thước của tập train: 3409576\n",
      "Kích thước của tập test: 852395\n",
      "Successfullll !!!!\n"
     ]
    }
   ],
   "source": [
    "# 2. Chuẩn bị dữ liệu\n",
    "# 2.1 Đọc và lọc dataset\n",
    "def load_and_filter_data(data_path, min_elo=2300):\n",
    "    df = pd.read_csv(data_path)\n",
    "    df = df[(df['WhiteElo'] > min_elo) & (df['BlackElo'] > min_elo)]\n",
    "    print(f\"Số ván cờ sau khi lọc: {len(df)}\")\n",
    "    if len(df) == 0:\n",
    "        raise ValueError(f\"Không có ván cờ nào thỏa mãn min_elo={min_elo}\")\n",
    "    return df\n",
    "\n",
    "# 2.2 Tạo danh sách các ván cờ\n",
    "def create_game_list(df):\n",
    "    game_list = []\n",
    "    invalid_games = 0\n",
    "    for index, row in df.iterrows():\n",
    "        pgn = row['AN']\n",
    "        board = chess.Board()\n",
    "        moves = []\n",
    "        tokens = pgn.split()\n",
    "        for token in tokens:\n",
    "            if token in ['1-0', '0-1', '1/2-1/2']:\n",
    "                break\n",
    "            if (token[0].isdigit() or token in ['...', '{', '}', '[%eval', '[%clk'] or\n",
    "                any(s in token for s in ['?!', '??', '!?', '!', '?', '#'])):\n",
    "                continue\n",
    "            try:\n",
    "                move_obj = board.parse_san(token)\n",
    "                moves.append(move_obj.uci())\n",
    "                board.push(move_obj)\n",
    "            except Exception as e:\n",
    "                invalid_games += 1\n",
    "                break\n",
    "        if moves:\n",
    "            game_list.append(\" \".join(moves))\n",
    "    print(f\"Số ván cờ trong game_list: {len(game_list)}\")\n",
    "    print(f\"Số ván cờ bị bỏ qua do lỗi: {invalid_games}\")\n",
    "    return game_list\n",
    "\n",
    "# 2.3 Tạo cặp (chuỗi nước đi, nước đi tiếp theo)\n",
    "def create_move_sequences(game_list, max_moves=30, save_path=\"/kaggle/working/chess_data.pkl\", mapping_path=\"/kaggle/working/move_mappings.pkl\"):\n",
    "    print(f\"RAM available: {psutil.virtual_memory().available / 1024**3:.2f} GB\")\n",
    "    move_to_idx = defaultdict(lambda: len(move_to_idx))\n",
    "    X, y = [], []\n",
    "    batch_size = 100000\n",
    "    batch_count = 0\n",
    "    batch_files = []\n",
    "    \n",
    "    for pgn in game_list:\n",
    "        if not pgn.strip():\n",
    "            continue\n",
    "        moves = pgn.split()\n",
    "        if not moves:\n",
    "            continue\n",
    "        for i in range(len(moves)):\n",
    "            sequence = moves[max(0, i - max_moves):i]\n",
    "            sequence_idx = [move_to_idx[move] for move in sequence]\n",
    "            padded_sequence = [0] * (max_moves - len(sequence_idx)) + sequence_idx\n",
    "            X.append(padded_sequence)\n",
    "            y.append(move_to_idx[moves[i]])\n",
    "            \n",
    "            if len(X) >= batch_size:\n",
    "                data = {\n",
    "                    'X': np.array(X, dtype=np.int32),\n",
    "                    'y': np.array(y, dtype=np.int32),\n",
    "                    'move_to_idx': dict(move_to_idx),\n",
    "                    'idx_to_move': {v: k for k, v in move_to_idx.items()}\n",
    "                }\n",
    "                batch_path = f\"{save_path}_batch_{batch_count}.pkl\"\n",
    "                with open(batch_path, 'wb') as f:\n",
    "                    pickle.dump(data, f)\n",
    "                print(f\"Đã lưu batch {batch_count} tại: {batch_path}\")\n",
    "                batch_files.append(batch_path)\n",
    "                X, y = [], []\n",
    "                batch_count += 1\n",
    "    \n",
    "    # Lưu batch cuối nếu còn\n",
    "    if X:\n",
    "        data = {\n",
    "            'X': np.array(X, dtype=np.int32),\n",
    "            'y': np.array(y, dtype=np.int32),\n",
    "            'move_to_idx': dict(move_to_idx),\n",
    "            'idx_to_move': {v: k for k, v in move_to_idx.items()}\n",
    "        }\n",
    "        batch_path = save_path\n",
    "        with open(batch_path, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "        print(f\"Đã lưu batch cuối tại: {batch_path}\")\n",
    "        batch_files.append(batch_path)\n",
    "    \n",
    "    # Lưu toàn bộ move_to_idx và idx_to_move vào file riêng\n",
    "    mappings = {\n",
    "        'move_to_idx': dict(move_to_idx),\n",
    "        'idx_to_move': {v: k for k, v in move_to_idx.items()}\n",
    "    }\n",
    "    with open(mapping_path, 'wb') as f:\n",
    "        pickle.dump(mappings, f)\n",
    "    print(f\"Đã lưu toàn bộ move_to_idx và idx_to_move tại: {mapping_path}\")\n",
    "    \n",
    "    # Gộp tất cả batch vào X, y\n",
    "    X_all, y_all = [], []\n",
    "    for batch_path in batch_files:\n",
    "        with open(batch_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            X_all.extend(data['X'].tolist())\n",
    "            y_all.extend(data['y'].tolist())\n",
    "    \n",
    "    print(f\"Tổng số mẫu: {len(X_all)}\")\n",
    "    return np.array(X_all, dtype=np.int32), np.array(y_all, dtype=np.int32), dict(move_to_idx), dict(mappings['idx_to_move'])\n",
    "\n",
    "# 2.4 Chia dữ liệu\n",
    "def split_data(X, y, test_size=0.2):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# 2.5 Tạo Dataset và DataLoader\n",
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return torch.tensor(self.X[index], dtype=torch.long), torch.tensor(self.y[index], dtype=torch.long)\n",
    "\n",
    "# 2.6 Chuẩn bị dữ liệu\n",
    "def prepare_data(data_path, pkl_path=\"/kaggle/working/chess_data.pkl\", mapping_path=\"/kaggle/working/move_mappings.pkl\"):\n",
    "    print(\"Tạo dữ liệu mới và ghi đè file .pkl...\")\n",
    "    df = load_and_filter_data(data_path)\n",
    "    game_list = create_game_list(df)\n",
    "    X, y, move_to_idx, idx_to_move = create_move_sequences(game_list, save_path=pkl_path, mapping_path=mapping_path)\n",
    "\n",
    "    # In move_to_idx và idx_to_move (chỉ in 5 mục đầu tiên để tránh quá dài)\n",
    "    print(\"\\nmove_to_idx (5 mục đầu tiên):\")\n",
    "    print(dict(list(move_to_idx.items())[:5]))\n",
    "    print(f\"Tổng số mục trong move_to_idx: {len(move_to_idx)}\")\n",
    "    print(\"\\nidx_to_move (5 mục đầu tiên):\")\n",
    "    print(dict(list(idx_to_move.items())[:5]))\n",
    "    print(f\"Tổng số mục trong idx_to_move: {len(idx_to_move)}\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "    \n",
    "    train_dataset = ChessDataset(X_train, y_train)\n",
    "    test_dataset = ChessDataset(X_test, y_test)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    \n",
    "    print(f\"Số lượng mini-batches train: {len(train_loader)}\")\n",
    "    print(f\"Kích thước của tập train: {len(train_loader.dataset)}\")\n",
    "    print(f\"Kích thước của tập test: {len(test_loader.dataset)}\")\n",
    "    print(\"Successfullll !!!!\")\n",
    "    \n",
    "    return train_loader, test_loader, move_to_idx, idx_to_move\n",
    "\n",
    "# Gọi hàm chuẩn bị dữ liệu\n",
    "train_loader, test_loader, move_to_idx, idx_to_move = prepare_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce617c55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T12:23:08.910603Z",
     "iopub.status.busy": "2025-05-18T12:23:08.910063Z",
     "iopub.status.idle": "2025-05-18T12:23:09.178411Z",
     "shell.execute_reply": "2025-05-18T12:23:09.177444Z"
    },
    "papermill": {
     "duration": 0.27421,
     "end_time": "2025-05-18T12:23:09.179633",
     "exception": false,
     "start_time": "2025-05-18T12:23:08.905423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số tham số: 27,158,357\n",
      "Successful\n"
     ]
    }
   ],
   "source": [
    "# 3. Model Engineering\n",
    "# 3.1 Định nghĩa mô hình Transformer\n",
    "class ChessMovePredictor(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=512, num_heads=8, num_layers=8, max_moves=30, dropout=0.2):\n",
    "        super(ChessMovePredictor, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.pos_encoding = nn.Parameter(torch.zeros(1, max_moves, embed_dim))\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim, \n",
    "            nhead=num_heads, \n",
    "            batch_first=True, \n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(embed_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x) + self.pos_encoding\n",
    "        x = self.transformer(x)\n",
    "        x = x[:, -1, :]  # Lấy embedding của nước đi cuối\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 3.2 Khởi tạo mô hình\n",
    "vocab_size = len(move_to_idx)\n",
    "model = ChessMovePredictor(vocab_size=vocab_size)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# In số lượng tham số\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Tổng số tham số: {total_params:,}\")\n",
    "print(\"Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76d092c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T12:23:09.188652Z",
     "iopub.status.busy": "2025-05-18T12:23:09.188422Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2025-05-18T12:23:09.183664",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 0/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 640000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 1280000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 1920000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 2560000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 3200000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.1449 | Top-1 Acc: 0.1895 | Top-3 Acc: 0.3396 | Top-5 Acc: 0.4181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3.5117 | Top-1 Acc: 0.2313 | Top-3 Acc: 0.4109 | Top-5 Acc: 0.5024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu checkpoint tại: /kaggle/working/training_checkpoints/ckpt_epoch_1.pt\n",
      "Epoch 2\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 0/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 640000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 1280000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 1920000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 2560000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 3200000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.4216 | Top-1 Acc: 0.2376 | Top-3 Acc: 0.4210 | Top-5 Acc: 0.5145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3.2077 | Top-1 Acc: 0.2561 | Top-3 Acc: 0.4487 | Top-5 Acc: 0.5457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu checkpoint tại: /kaggle/working/training_checkpoints/ckpt_epoch_2.pt\n",
      "Epoch 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 0/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 640000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 1280000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 1920000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 2560000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 3200000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.1976 | Top-1 Acc: 0.2558 | Top-3 Acc: 0.4503 | Top-5 Acc: 0.5485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3.0609 | Top-1 Acc: 0.2699 | Top-3 Acc: 0.4703 | Top-5 Acc: 0.5701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu checkpoint tại: /kaggle/working/training_checkpoints/ckpt_epoch_3.pt\n",
      "Epoch 4\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 0/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 640000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 1280000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 1920000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 2560000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 3200000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.0642 | Top-1 Acc: 0.2685 | Top-3 Acc: 0.4707 | Top-5 Acc: 0.5718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.9520 | Top-1 Acc: 0.2801 | Top-3 Acc: 0.4868 | Top-5 Acc: 0.5888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu checkpoint tại: /kaggle/working/training_checkpoints/ckpt_epoch_4.pt\n",
      "Epoch 5\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 0/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 640000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 1280000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 1920000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 2560000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 3200000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.9795 | Top-1 Acc: 0.2777 | Top-3 Acc: 0.4856 | Top-5 Acc: 0.5882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.9025 | Top-1 Acc: 0.2848 | Top-3 Acc: 0.4955 | Top-5 Acc: 0.5987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu checkpoint tại: /kaggle/working/training_checkpoints/ckpt_epoch_5.pt\n",
      "Epoch 6\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 0/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 640000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 1280000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 1920000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 2560000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 3200000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.9222 | Top-1 Acc: 0.2844 | Top-3 Acc: 0.4965 | Top-5 Acc: 0.6002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.8695 | Top-1 Acc: 0.2907 | Top-3 Acc: 0.5037 | Top-5 Acc: 0.6075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu checkpoint tại: /kaggle/working/training_checkpoints/ckpt_epoch_6.pt\n",
      "Epoch 7\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 0/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 640000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 1280000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 1920000/3409576 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 2560000/3409576 samples\n"
     ]
    }
   ],
   "source": [
    "# 4. Training the Model\n",
    "# 4.1 Establish Checkpoints\n",
    "checkpoint_dir = '/kaggle/working/training_checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# 4.2 Build Training Loop\n",
    "def print_train_time(start, end):\n",
    "    total_time = end - start\n",
    "    print(f\"Training Time: {total_time:.2f} seconds\")\n",
    "    return total_time\n",
    "\n",
    "# THÊM TOP-K ACCURACY\n",
    "def top_k_accuracy(output, target, k=5):\n",
    "    with torch.no_grad():\n",
    "        _, pred = output.topk(k, dim=1)\n",
    "        correct = pred.eq(target.view(-1, 1).expand_as(pred))\n",
    "        return correct.any(dim=1).float().mean().item()\n",
    "\n",
    "def train_model(model, train_loader, test_loader, epochs, learning_rate, checkpoint_path=None):\n",
    "    torch.manual_seed(42)\n",
    "    train_time_start = timer()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "    start_epoch = 0\n",
    "    if checkpoint_path and os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        print(f\"Tiếp tục từ epoch {start_epoch}\")\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        print(f\"Epoch {epoch + 1}\\n------------------------------\")\n",
    "        \n",
    "        # Training\n",
    "        train_loss = 0\n",
    "        train_top1_acc, train_top3_acc, train_top5_acc = 0, 0, 0\n",
    "        model.train()\n",
    "        for batch, (X, y) in enumerate(train_loader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            output = model(X)\n",
    "            loss = loss_fn(output, y)\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # Tính Top-k Accuracy\n",
    "            train_top1_acc += top_k_accuracy(output, y, k=1)\n",
    "            train_top3_acc += top_k_accuracy(output, y, k=3)\n",
    "            train_top5_acc += top_k_accuracy(output, y, k=5)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch % 10000 == 0:\n",
    "                print(f\"Looked at {batch * 64}/{len(train_loader.dataset)} samples\")\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_top1_acc /= len(train_loader)\n",
    "        train_top3_acc /= len(train_loader)\n",
    "        train_top5_acc /= len(train_loader)\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Top-1 Acc: {train_top1_acc:.4f} | Top-3 Acc: {train_top3_acc:.4f} | Top-5 Acc: {train_top5_acc:.4f}\")\n",
    "\n",
    "        # Testing\n",
    "        test_loss = 0\n",
    "        test_top1_acc, test_top3_acc, test_top5_acc = 0, 0, 0\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            for X, y in test_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                output = model(X)\n",
    "                test_loss += loss_fn(output, y).item()\n",
    "                \n",
    "                # Tính Top-k Accuracy\n",
    "                test_top1_acc += top_k_accuracy(output, y, k=1)\n",
    "                test_top3_acc += top_k_accuracy(output, y, k=3)\n",
    "                test_top5_acc += top_k_accuracy(output, y, k=5)\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_top1_acc /= len(test_loader)\n",
    "        test_top3_acc /= len(test_loader)\n",
    "        test_top5_acc /= len(test_loader)\n",
    "        print(f\"Test Loss: {test_loss:.4f} | Top-1 Acc: {test_top1_acc:.4f} | Top-3 Acc: {test_top3_acc:.4f} | Top-5 Acc: {test_top5_acc:.4f}\")\n",
    "\n",
    "        # Lưu checkpoint\n",
    "        checkpoint_path_save = os.path.join(checkpoint_dir, f'ckpt_epoch_{epoch + 1}.pt')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'test_loss': test_loss,\n",
    "            'train_top1_acc': train_top1_acc,\n",
    "            'test_top1_acc': test_top1_acc,\n",
    "        }, checkpoint_path_save)\n",
    "        print(f\"Đã lưu checkpoint tại: {checkpoint_path_save}\")\n",
    "\n",
    "    train_time_end = timer()\n",
    "    print_train_time(train_time_start, train_time_end)\n",
    "\n",
    "# 4.3 Chạy huấn luyện\n",
    "train_model(model, train_loader, test_loader, epochs=10, learning_rate=0.0001)\n",
    "\n",
    "# Để tiếp tục từ checkpoint (ví dụ từ epoch cụ thể):\n",
    "# def load_mappings(mapping_path):\n",
    "#     with open(mapping_path, 'rb') as f:\n",
    "#         mappings = pickle.load(f)\n",
    "#     return mappings['move_to_idx'], mappings['idx_to_move']\n",
    "\n",
    "# # Tải ánh xạ từ file .pkl\n",
    "# move_to_idx, idx_to_move = load_mappings(\"/kaggle/input/transformer-chessbot/move_mappings.pkl\")\n",
    "\n",
    "# # Khởi tạo mô hình với vocab_size dựa trên move_to_idx\n",
    "# vocab_size = len(move_to_idx)\n",
    "# model = ChessMovePredictor(vocab_size=vocab_size)\n",
    "# model.to(device)\n",
    "# checkpoint_to_load = '/kaggle/input/transformer-chessbot/training_checkpoints/ckpt_epoch_20.pt'\n",
    "# train_model(model, train_loader, test_loader, epochs=30, learning_rate=0.0001, checkpoint_path=checkpoint_to_load)\n",
    "\n",
    "print(\"Successful !\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1159749,
     "sourceId": 1944111,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-18T12:19:05.942543",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
